{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n",
      "65536/57026 [==================================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4 12.1 17.9 23.1 19.9\n",
      " 15.7  8.8 50.  22.5 24.1 27.5 10.9 30.8 32.9 24.  18.5 13.3 22.9 34.7\n",
      " 16.6 17.5 22.3 16.1 14.9 23.1 34.9 25.  13.9 13.1 20.4 20.  15.2 24.7\n",
      " 22.2 16.7 12.7 15.6 18.4 21.  30.1 15.1 18.7  9.6 31.5 24.8 19.1 22.\n",
      " 14.5 11.  32.  29.4 20.3 24.4 14.6 19.5 14.1 14.3 15.6 10.5  6.3 19.3\n",
      " 19.3 13.4 36.4 17.8 13.5 16.5  8.3 14.3 16.  13.4 28.6 43.5 20.2 22.\n",
      " 23.  20.7 12.5 48.5 14.6 13.4 23.7 50.  21.7 39.8 38.7 22.2 34.9 22.5\n",
      " 31.1 28.7 46.  41.7 21.  26.6 15.  24.4 13.3 21.2 11.7 21.7 19.4 50.\n",
      " 22.8 19.7 24.7 36.2 14.2 18.9 18.3 20.6 24.6 18.2  8.7 44.  10.4 13.2\n",
      " 21.2 37.  30.7 22.9 20.  19.3 31.7 32.  23.1 18.8 10.9 50.  19.6  5.\n",
      " 14.4 19.8 13.8 19.6 23.9 24.5 25.  19.9 17.2 24.6 13.5 26.6 21.4 11.9\n",
      " 22.6 19.6  8.5 23.7 23.1 22.4 20.5 23.6 18.4 35.2 23.1 27.9 20.6 23.7\n",
      " 28.  13.6 27.1 23.6 20.6 18.2 21.7 17.1  8.4 25.3 13.8 22.2 18.4 20.7\n",
      " 31.6 30.5 20.3  8.8 19.2 19.4 23.1 23.  14.8 48.8 22.6 33.4 21.1 13.6\n",
      " 32.2 13.1 23.4 18.9 23.9 11.8 23.3 22.8 19.6 16.7 13.4 22.2 20.4 21.8\n",
      " 26.4 14.9 24.1 23.8 12.3 29.1 21.  19.5 23.3 23.8 17.8 11.5 21.7 19.9\n",
      " 25.  33.4 28.5 21.4 24.3 27.5 33.1 16.2 23.3 48.3 22.9 22.8 13.1 12.7\n",
      " 22.6 15.  15.3 10.5 24.  18.5 21.7 19.5 33.2 23.2  5.  19.1 12.7 22.3\n",
      " 10.2 13.9 16.3 17.  20.1 29.9 17.2 37.3 45.4 17.8 23.2 29.  22.  18.\n",
      " 17.4 34.6 20.1 25.  15.6 24.8 28.2 21.2 21.4 23.8 31.  26.2 17.4 37.9\n",
      " 17.5 20.   8.3 23.9  8.4 13.8  7.2 11.7 17.1 21.6 50.  16.1 20.4 20.6\n",
      " 21.4 20.6 36.5  8.5 24.8 10.8 21.9 17.3 18.9 36.2 14.9 18.2 33.3 21.8\n",
      " 19.7 31.6 24.8 19.4 22.8  7.5 44.8 16.8 18.7 50.  50.  19.5 20.1 50.\n",
      " 17.2 20.8 19.3 41.3 20.4 20.5 13.8 16.5 23.9 20.6 31.5 23.3 16.8 14.\n",
      " 33.8 36.1 12.8 18.3 18.7 19.1 29.  30.1 50.  50.  22.  11.9 37.6 50.\n",
      " 22.7 20.8 23.5 27.9 50.  19.3 23.9 22.6 15.2 21.7 19.2 43.8 20.3 33.2\n",
      " 19.9 22.5 32.7 22.  17.1 19.  15.  16.1 25.1 23.7 28.7 37.2 22.6 16.4\n",
      " 25.  29.8 22.1 17.4 18.1 30.3 17.5 24.7 12.6 26.5 28.7 13.3 10.4 24.4\n",
      " 23.  20.  17.8  7.  11.8 24.4 13.8 19.4 25.2 19.4 19.4 29.1]\n"
     ]
    }
   ],
   "source": [
    "print(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "# test data를 정규화 할 때도 test set를 사용하면 안된다!\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross-vaildation을 사용한 훈련 검증🧨\n",
    "<br/>\n",
    "샘플이 적은 경우, 이전과 같이 데이터를 훈련 셋과 검증 셋으로 나누기 부담스럽다.\n",
    "<p>\n",
    "이런 상황에 가장 좋은 방법은 k-fold cross-vaildation을 사용하는 것이다.<br/>\n",
    "쉽게 데이터를 K개로 분할해 K개의 모델을 각각 만들어 K-1의 분할을 해서 평가하는 방법이다.<br/>\n",
    "검증 점수는 K개의 검증 점수 평균이 된다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드 # 0\n",
      "처리중인 폴드 # 1\n",
      "처리중인 폴드 # 2\n",
      "처리중인 폴드 # 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(train_data)//k\n",
    "num_epochs = 100\n",
    "all_score = []\n",
    "for i in range(k):\n",
    "    print('처리중인 폴드 #', i)\n",
    "    val_data = train_data[i*num_val_samples: (i+1) * num_val_samples]\n",
    "    val_target = train_targets[i*num_val_samples: (i+1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i*num_val_samples],\n",
    "        train_data[(i+1)*num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "    partial_train_target = np.concatenate(\n",
    "        [train_targets[:i*num_val_samples],\n",
    "        train_targets[(i+1)*num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_target, epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_target, verbose=1)\n",
    "    all_score.append(val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.11679458618164]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.11679458618164]\n"
     ]
    }
   ],
   "source": [
    "print(all_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드 # 0\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 205.9149 - mae: 10.7700 - val_loss: 39.3426 - val_mae: 3.9463\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 34.1216 - mae: 3.9898 - val_loss: 24.1098 - val_mae: 3.2488\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 24.0691 - mae: 3.2968 - val_loss: 19.5830 - val_mae: 2.8664\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 20.3483 - mae: 3.0218 - val_loss: 16.7464 - val_mae: 2.5913\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 17.8615 - mae: 2.7994 - val_loss: 14.7206 - val_mae: 2.4979\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 15.6415 - mae: 2.6601 - val_loss: 13.3107 - val_mae: 2.3075\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 15.1980 - mae: 2.5592 - val_loss: 13.8370 - val_mae: 2.3634\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 14.3679 - mae: 2.5012 - val_loss: 11.1468 - val_mae: 2.1196\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 13.1550 - mae: 2.4718 - val_loss: 10.5113 - val_mae: 2.0359\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.7421 - mae: 2.4324 - val_loss: 10.7916 - val_mae: 2.1345\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.9913 - mae: 2.3707 - val_loss: 9.6327 - val_mae: 2.0690\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.3833 - mae: 2.3367 - val_loss: 9.3199 - val_mae: 2.0056\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.7898 - mae: 2.2886 - val_loss: 9.6725 - val_mae: 2.0914\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.7976 - mae: 2.2467 - val_loss: 9.4888 - val_mae: 2.0322\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.5343 - mae: 2.2153 - val_loss: 9.0333 - val_mae: 1.9150\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.7359 - mae: 2.2526 - val_loss: 9.0058 - val_mae: 2.0910\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.2230 - mae: 2.1447 - val_loss: 9.5565 - val_mae: 1.9458\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.0352 - mae: 2.1709 - val_loss: 9.5931 - val_mae: 2.2820\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.2551 - mae: 2.1496 - val_loss: 8.4855 - val_mae: 1.9391\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.8278 - mae: 2.1578 - val_loss: 8.4989 - val_mae: 1.8494\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.1140 - mae: 2.0805 - val_loss: 8.3237 - val_mae: 1.9538\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.0609 - mae: 2.0610 - val_loss: 8.5896 - val_mae: 1.9565\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.9457 - mae: 2.0595 - val_loss: 8.4868 - val_mae: 2.0414\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.7336 - mae: 2.0322 - val_loss: 9.7718 - val_mae: 2.3015\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.8481 - mae: 2.0207 - val_loss: 8.5217 - val_mae: 1.8592\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.4947 - mae: 1.9860 - val_loss: 7.8401 - val_mae: 1.8385\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.9797 - mae: 1.9402 - val_loss: 7.9151 - val_mae: 1.9341\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.6814 - mae: 1.9153 - val_loss: 8.3079 - val_mae: 1.9669\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.9602 - mae: 1.9723 - val_loss: 8.0359 - val_mae: 1.8727\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.7901 - mae: 1.9694 - val_loss: 8.0227 - val_mae: 1.9859\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.2235 - mae: 1.8235 - val_loss: 8.6663 - val_mae: 1.9711\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.2700 - mae: 1.9023 - val_loss: 8.1030 - val_mae: 1.8842\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.7262 - mae: 1.8680 - val_loss: 7.9839 - val_mae: 1.9896\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0129 - mae: 1.8654 - val_loss: 10.3438 - val_mae: 2.3410\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.2504 - mae: 1.8933 - val_loss: 8.7843 - val_mae: 2.2429\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.8716 - mae: 1.8765 - val_loss: 8.0060 - val_mae: 1.8069\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.6307 - mae: 1.8011 - val_loss: 9.2665 - val_mae: 2.1237\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5705 - mae: 1.8161 - val_loss: 8.0580 - val_mae: 2.1441\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.6207 - mae: 1.7878 - val_loss: 7.7803 - val_mae: 1.9238\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5892 - mae: 1.7931 - val_loss: 8.6123 - val_mae: 1.9389\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5327 - mae: 1.7761 - val_loss: 8.0921 - val_mae: 1.8676\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.2653 - mae: 1.7416 - val_loss: 11.2823 - val_mae: 2.5492\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.0172 - mae: 1.8368 - val_loss: 8.3754 - val_mae: 2.1093\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.9227 - mae: 1.7220 - val_loss: 7.8464 - val_mae: 1.9099\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.9849 - mae: 1.7486 - val_loss: 10.1395 - val_mae: 2.1050\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.0939 - mae: 1.7057 - val_loss: 8.3868 - val_mae: 2.0534\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.8872 - mae: 1.7055 - val_loss: 8.3401 - val_mae: 2.1722\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.1046 - mae: 1.7047 - val_loss: 8.7170 - val_mae: 2.0268\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2759 - mae: 1.6837 - val_loss: 10.1105 - val_mae: 2.5366\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2842 - mae: 1.7215 - val_loss: 7.9535 - val_mae: 1.8968\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.5297 - mae: 1.6809 - val_loss: 8.7613 - val_mae: 2.0554\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.7933 - mae: 1.6950 - val_loss: 7.8832 - val_mae: 2.0849\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.3557 - mae: 1.5824 - val_loss: 9.3836 - val_mae: 2.3356\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2456 - mae: 1.6452 - val_loss: 8.5975 - val_mae: 1.8298\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.3845 - mae: 1.6211 - val_loss: 7.8253 - val_mae: 1.7840\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.0956 - mae: 1.6507 - val_loss: 8.2258 - val_mae: 1.8101\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.0940 - mae: 1.5461 - val_loss: 8.9801 - val_mae: 2.2911\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.9875 - mae: 1.6235 - val_loss: 8.5420 - val_mae: 2.0078\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6957 - mae: 1.5327 - val_loss: 9.5015 - val_mae: 2.1781\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7989 - mae: 1.5883 - val_loss: 7.8304 - val_mae: 1.8310\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.0118 - mae: 1.5583 - val_loss: 8.3280 - val_mae: 2.0818\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6737 - mae: 1.5058 - val_loss: 9.4344 - val_mae: 2.1735\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8432 - mae: 1.6081 - val_loss: 8.0631 - val_mae: 2.0481\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4193 - mae: 1.5093 - val_loss: 9.5226 - val_mae: 2.4270\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6427 - mae: 1.6249 - val_loss: 8.2862 - val_mae: 2.0143\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3286 - mae: 1.4915 - val_loss: 7.9853 - val_mae: 2.1102\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6923 - mae: 1.5545 - val_loss: 7.9831 - val_mae: 2.0329\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1821 - mae: 1.4749 - val_loss: 7.6494 - val_mae: 1.9332\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4801 - mae: 1.5246 - val_loss: 8.1798 - val_mae: 1.9729\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.5325 - mae: 1.4957 - val_loss: 7.5869 - val_mae: 1.8803\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3836 - mae: 1.4572 - val_loss: 7.8807 - val_mae: 2.1239\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0660 - mae: 1.4786 - val_loss: 7.8958 - val_mae: 2.0703\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4583 - mae: 1.5214 - val_loss: 10.6123 - val_mae: 2.5340\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4420 - mae: 1.5028 - val_loss: 7.6762 - val_mae: 1.9463\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1423 - mae: 1.5261 - val_loss: 8.9060 - val_mae: 2.0757\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1772 - mae: 1.4616 - val_loss: 8.6397 - val_mae: 2.1797\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1333 - mae: 1.4818 - val_loss: 7.5231 - val_mae: 1.9393\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8125 - mae: 1.5002 - val_loss: 7.6346 - val_mae: 1.9503\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3820 - mae: 1.3960 - val_loss: 8.3153 - val_mae: 1.9826\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1036 - mae: 1.4831 - val_loss: 8.0775 - val_mae: 2.0493\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8357 - mae: 1.4344 - val_loss: 9.2175 - val_mae: 2.0626\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8389 - mae: 1.4565 - val_loss: 7.6432 - val_mae: 2.0205\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7742 - mae: 1.4107 - val_loss: 8.2108 - val_mae: 2.0220\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7425 - mae: 1.4306 - val_loss: 9.6133 - val_mae: 2.3413\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3952 - mae: 1.4131 - val_loss: 9.9396 - val_mae: 2.1588\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6184 - mae: 1.4165 - val_loss: 9.1209 - val_mae: 2.1717\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2798 - mae: 1.3998 - val_loss: 8.3194 - val_mae: 2.0650\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4950 - mae: 1.3840 - val_loss: 8.5389 - val_mae: 2.1329\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5077 - mae: 1.4036 - val_loss: 8.9796 - val_mae: 2.0870\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0933 - mae: 1.4054 - val_loss: 7.5440 - val_mae: 1.9965\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2758 - mae: 1.3797 - val_loss: 9.8864 - val_mae: 2.3086\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1670 - mae: 1.3364 - val_loss: 12.3531 - val_mae: 2.6823\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5178 - mae: 1.4016 - val_loss: 9.2850 - val_mae: 2.2458\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2093 - mae: 1.3327 - val_loss: 10.7643 - val_mae: 2.4290\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1487 - mae: 1.3637 - val_loss: 9.2752 - val_mae: 2.1994\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9628 - mae: 1.3719 - val_loss: 10.1769 - val_mae: 2.4389\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8689 - mae: 1.3316 - val_loss: 8.4700 - val_mae: 2.1075\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.9830 - mae: 1.3546 - val_loss: 8.6239 - val_mae: 2.1049\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.0027 - mae: 1.3317 - val_loss: 8.6690 - val_mae: 2.1565\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0642 - mae: 1.3261 - val_loss: 8.5440 - val_mae: 2.1437\n",
      "Epoch 101/500\n",
      "  1/303 [..............................] - ETA: 0s - loss: 0.0691 - mae: 0.2628"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "all_score = []\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('처리중인 폴드 #', i)\n",
    "    val_data = train_data[i*num_val_samples: (i+1) * num_val_samples]\n",
    "    val_target = train_targets[i*num_val_samples: (i+1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i*num_val_samples],\n",
    "        train_data[(i+1)*num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "    partial_train_target = np.concatenate(\n",
    "        [train_targets[:i*num_val_samples],\n",
    "        train_targets[(i+1)*num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_target, \n",
    "                        validation_data=(val_data, val_target),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    mae_history = history.history['val_mean_absoulte_error']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74269b44421b5226088cbe396a698e57b32e99aa8b9587c89bc5a30ffed5a971"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('kaggle': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
