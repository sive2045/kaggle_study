{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, vaildation and test set 🛠\n",
    "<p>\n",
    "    모델 평가의 핵심은 데이터를 train, vaildation과 test로 구분하는 것이다.<br>\n",
    "    이렇게하는 주된 이유는 test set은 평가할 때 딱 한번만 사용하기 위해서다.<br>\n",
    "    보통 학습할 때 그 정보를 바탕으로 hyperparameter를 튜닝하게 되는데, 이때<br>\n",
    "    imformation leak가 발생한다. 따라서 타당한 평가를 위해서 데이터셋을 구분<br>\n",
    "    하는것은 매우 중요하다.\n",
    "</p>\n",
    "<br/>\n",
    "\n",
    "## set vaildation data from train data 🔨\n",
    "<p>\n",
    "    train data를 나누는 것은 간단해보이지만, 데이터가 적을 때 매우 큰 효율을 야기한다.\n",
    "</p>\n",
    "<br/>종류\n",
    "<ul>\n",
    "    <li>hold-out vaildation</li>\n",
    "    <li>k-fold cross-vaildation</li>\n",
    "    <li>iterated k-fold cross-vaildation</li>\n",
    "</ul>\n",
    "\n",
    "### hold-out vaildation ⚽\n",
    "<p>\n",
    "    데이터의 일정량을 검증 세트로 떼어 놓는 방식이다. 남은 데이터에서 <br>\n",
    "    훈련하고 검증 세트로 평가를 한다. 정보 누설을 피하기위해 검증 세트<br>\n",
    "    는 따로 떼어 놓는다.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out vaildation 구현 예시\n",
    "import numpy as np\n",
    "\n",
    "data = np.linspace(1,1000000,num=100000000)\n",
    "\n",
    "num_vaildation_samples = 1000\n",
    "\n",
    "np.random.shuffle(data) # 데이터를 섞는 것이 일반적으로 좋음\n",
    "\n",
    "validation_data = data[:num_vaildation_samples] # 검증 데이터를 생성함\n",
    "data = data[num_vaildation_samples:]\n",
    "\n",
    "training_data = data[:] # 훈련세트를 생성함\n",
    "\n",
    "\"\"\"\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "vaildation_score = model.evaluate(vaildation_data) # 검증 데이터로 평가함\n",
    "\n",
    "#모델 튜닝 작업\n",
    "#훈련, 평가 튜닝 반복 ...\n",
    "\n",
    "model = get_model()\n",
    "model.train(np.concatenate([train_data,         # hyperparameter의 튜닝 작업이 끝나면, \n",
    "                            vaildation_data]))  # 다시 모든 데이터를 통해 훈련시킴\n",
    "test_score = model.evaluate(test_data)          # test data를 통해 최종 평가를 함\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    이 방법은 단순하기에 한 가지 단점이 있다. 데이터가 매우 적을때에는 <br>\n",
    "    검증 세트와 테스트 세트가 전체 데이터의 통계적인 대표를 못할 수 있다.<br>\n",
    "</p>\n",
    "<br/>\n",
    "\n",
    "### k-fold cross-vaildation ⚾\n",
    "<p>\n",
    "    hold-out의 단점을 보안하고자 나온 방식이다. 주어진 데이터를 k개로 분할<br>\n",
    "    한다. 각 fold에서 i번째 데이터는 vaildation으로 이용하고 k-1 데이터들은<br>\n",
    "    훈련에 사용하는 방식이다. 최종 평가는 이렇게 얻은 k개의 점수를 평균을 <br>\n",
    "    통해 얻는다.\n",
    "</p>\n",
    "<img src=\"./k_fold.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=4\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "validation_scores = []\n",
    "\n",
    "for fold in range(k):\n",
    "    \"\"\"\n",
    "    train data로부터 인덱싱 하는 과정을 \n",
    "    주의 깊게 봐보자\n",
    "    \"\"\"\n",
    "    validation_data = data[num_validation_samples * fold:\n",
    "        num_validation_samples * (fold + 1)]\n",
    "    training_data = data[:num_validation_samples * fold] + \\\n",
    "        data[num_validation_samples * (fold + 1):]\n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "validation_score = np.average(validation_scores)\n",
    "model = get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITERATED K-FOLD VALIDATION WITH SHUFFLING 🥎\n",
    "<p>\n",
    "    비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자<br>\n",
    "    할 때 사용하는 방법이다. 이 방법은 k-fold를 여러번 적용하되<br>\n",
    "    k개 분할 전 데이터를 shufffling하는 방법이다. </br>\n",
    "    최종 점수는 모든 k-겹 교차 검증을 실행해 얻은 점수의 평균이다<br>\n",
    "    결국 P * K개의 (P는 반복 횟수)의 모델을 훈련하고 평가하기에 <br>\n",
    "    cost가 비싸다.\n",
    "</p>\n",
    "\n",
    "# Things to keep in mind! 📜\n",
    "<ul>\n",
    "    <li>Data representativeness : 꼭 무작위로 데이터를 섞고 사용하자. 데이터가 일련으로 정렬된 경우 편향된 학습을 할 수 있다.</li>\n",
    "    <li>The arrow of time : 한 예로 과거로부터 미래를 예측하려면, 데이터를 분할하기전 무작위로 섞어서는 절대 안된다! 방향이 섞이면 정보 누설이 생긴다. 시간의 방향은 항시 주의히자!</li>\n",
    "    <li>Redundancy in your data : 주어진 데이터에 중복 데이터가 포함돼있을 수도 있다. 분할 전에 중복 데이터를 제거해주자! 만약 분할 후 중복 데이터가 각각 훈련과 검증 데이터에 들어가면 최악의 경우가 된다!</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74269b44421b5226088cbe396a698e57b32e99aa8b9587c89bc5a30ffed5a971"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('kaggle': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
